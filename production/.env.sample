# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_CONTEXT_LENGTH=4096

# Provider Selection (ollama|claude|gemini|codex)
OLLAMA_CLI_PROVIDER=ollama

# Cloud Ollama (optional)
OLLAMA_CLOUD_HOST=
OLLAMA_CLOUD_API_KEY=

# Alternative Provider API Keys
ANTHROPIC_API_KEY=
GEMINI_API_KEY=
OPENAI_API_KEY=

# Provider Routing (per task type)
OLLAMA_CLI_CODING_PROVIDER=ollama
OLLAMA_CLI_CODING_MODEL=codestral:latest
OLLAMA_CLI_AGENT_PROVIDER=ollama
OLLAMA_CLI_AGENT_MODEL=llama3.2
OLLAMA_CLI_SUBAGENT_PROVIDER=ollama
OLLAMA_CLI_SUBAGENT_MODEL=llama3.2:3b

# Feature Flags
AUTO_COMPACT=true
COMPACT_THRESHOLD=0.85
HOOKS_ENABLED=true
